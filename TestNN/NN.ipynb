{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import numpy as np\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirName = \"../lettersketch/assets/train_images/\"\n",
      "fileNames = []\n",
      "fileLetters = []\n",
      "for fileName in os.listdir(dirName):\n",
      "    if fileName.endswith(\".png\") and (not \"__\" in fileName):\n",
      "       fileNames.append(dirName+fileName)\n",
      "       letter = fileName.split(\"_\")[1]\n",
      "       fileLetters.append(letter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.array([mpimg.imread(fileName) for fileName in fileNames], dtype = np.float64)\n",
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = data.reshape(50, 20*28)\n",
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for dt in np.nditer(data, op_flags=['readwrite']):\n",
      "    if (dt == 1.0):\n",
      "        dt[...] = 0.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print data[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imgplot = plt.imshow(data[9].reshape(20,28), cmap=\"gray\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAD6CAYAAAD+87+fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fe51d941d90>"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labelDict = {'E':0.0, 'F':1.0, 'H':2.0, 'I':3.0, 'L':4.0, 'T':5.0}\n",
      "print fileLetters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['L', 'L', 'F', 'F', 'F', 'H', 'F', 'F', 'I', 'F', 'L', 'E', 'H', 'F', 'L', 'I', 'L', 'L', 'E', 'H', 'T', 'F', 'I', 'H', 'I', 'T', 'I', 'T', 'L', 'H', 'E', 'E', 'I', 'I', 'T', 'F', 'H', 'T', 'E', 'H', 'E', 'F', 'L', 'F', 'E', 'F', 'L', 'H', 'T', 'T']\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileLabels = [labelDict[letter] for letter in fileLetters]\n",
      "print fileLabels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorizeLabels(label):\n",
      "    vector = np.zeros((6))\n",
      "    vector[label] = 1.0\n",
      "    return vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataLabels = np.array([vectorizeLabels(label) for label in fileLabels])\n",
      "print dataLabels[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.  0.  0.  1.  0.]\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "(50, 560)"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataLabels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "(50, 6)"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load nnutils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---------------------------------------------------\n",
      "# Utilities for working with a standard neural net\n",
      "#---------------------------------------------------\n",
      "import numpy as np\n",
      "import numpy.random as random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---------------------------------------------------\n",
      "# A neural net class\n",
      "#---------------------------------------------------\n",
      "class NeuralNet(object):\n",
      "\n",
      "  # Constructor\n",
      "  #   layers: vector of length numLayers containing the\n",
      "  #           the number of neurons in each layer\n",
      "  #   biases: initialized with random numbers except for first layer\n",
      "  #   weights: initialized with random numbers\n",
      "  def __init__(self, layers):\n",
      "\n",
      "    self.numLayers = len(layers)\n",
      "    self.numNeurons = layers\n",
      "    self.biases = [random.randn(layer, 1) for layer in layers[1:]]\n",
      "    self.weights = [random.randn(layer2, layer1) \n",
      "                    for layer1, layer2 in zip(layers[:-1], layers[1:])]\n",
      "    \n",
      "  # The activation function\n",
      "  def activationFunction(xx):\n",
      "\n",
      "    return 1.0/(1.0 + np.exp(-xx))\n",
      "\n",
      "  # Derivative of activation function\n",
      "  def derivActivationFunction(xx):\n",
      "\n",
      "    return activationFunction(xx)*(1.0 - activationFunction(xx))\n",
      "\n",
      "  # The feedforward output computation for the network\n",
      "  #   inputVector: (n, 1) array\n",
      "  #                n = number of inputs to network\n",
      "  #   outputVector: ????\n",
      "  def forwardCompute(self, inputVector):\n",
      "\n",
      "    outputVector = []\n",
      "    for bias, weight in zip(self.biases, self.weights):\n",
      "      xx = np.dot(weight, inputVector) + bias\n",
      "      outputVector = activationFunction(xx)\n",
      "\n",
      "    return outputVector\n",
      "  \n",
      "  # Batch stochastic gradient descent to find minimum of objective function\n",
      "  #   training_data:  [(x1,y1),(x2,y2),....]\n",
      "  #                   where x1, x2, x3, ... are input data vectors\n",
      "  #                         y1, y2, y3, ... are labels\n",
      "  #   max_iterations: number of iterations\n",
      "  #   batch_size:     size of training batch\n",
      "  #   learning_rate:  gradient descent parameter \n",
      "  def batchStochasticGradientDescent(self, training_data, max_iterations, batch_size,\n",
      "                                     learning_rate):\n",
      "\n",
      "    # Get the number of training images\n",
      "    nTrain = len(training_data)\n",
      "\n",
      "    # Loop thru iterations\n",
      "    for it in xrange(max_iterations):\n",
      "\n",
      "      # Shuffle the training data\n",
      "      random.shuffle(training_data)\n",
      "\n",
      "      # Choose subsets of the training data\n",
      "      batches = [ training_data[start:start+batch_size]\n",
      "                  for start in xrange(0, nTrain, batch_size) ]\n",
      "\n",
      "      # Loop thru subsets\n",
      "      for batch in batches:\n",
      "        self.updateBatch(batch, learning_rate)\n",
      "      \n",
      "      print \"Iteration {0} complete\".format(it)\n",
      "\n",
      "  # Partial update of weights and biases using gradient descent\n",
      "  # with back propagation\n",
      "  def updateBatch(self, batch, learning_rate): \n",
      "\n",
      "    # Initialize gradC_w and gradC_b\n",
      "    gradC_w = [np.zeros(w.shape) for w in self.weights]\n",
      "    gradC_b = [np.zeros(b.shape) for b in self.biases]\n",
      "\n",
      "    # Loop through samples in the batch\n",
      "    for xx, yy in batch:\n",
      "\n",
      "      # Compute correction to weights & biases using forward and backprop\n",
      "      delta_gradC_w, delta_gradC_b = self.updateGradient(xx, yy)\n",
      "\n",
      "      # Update the gradients\n",
      "      gradC_w = [grad + delta_grad for grad, delta_grad in zip(gradC_w, delta_gradC_w)]\n",
      "      gradC_b = [grad + delta_grad for grad, delta_grad in zip(gradC_b, delta_gradC_b)]\n",
      "\n",
      "    # Update the weight and biases\n",
      "    self.weights = [ weight - (learning_rate/len(batch))*grad\n",
      "                     for weight, grad in zip(self.weights, gradC_w) ]\n",
      "    self.biases  = [ bias - (learning_rate/len(batch))*grad\n",
      "                     for bias, grad in zip(self.biases, gradC_b) ]\n",
      "\n",
      "  # Forward and then backpropagation to compute the gradient of the objective function\n",
      "  def updateGradient(self, xx, yy):\n",
      "\n",
      "    # Initialize gradC_w and gradC_b\n",
      "    gradC_w = [np.zeros(w.shape) for w in self.weights]\n",
      "    gradC_b = [np.zeros(b.shape) for b in self.biases]\n",
      "\n",
      "    # Compute forward pass through net\n",
      "    # Initial activation value = input value\n",
      "    activationValue = xx\n",
      "    activationValues = [xx]\n",
      "    layerOutputValues = []\n",
      "\n",
      "    # Loop through layers\n",
      "    for weight, bias in zip(self.weights, self.biases):\n",
      "\n",
      "      layerOutputValue = np.dot(weight, inputValue) + bias\n",
      "      layerOutputValues.append(layerOutputValues)\n",
      "\n",
      "      activationValue = activationFunction(layerOutputValue)\n",
      "      activationValues.append(activationValue)\n",
      "      \n",
      "    # Compute backpropagation corrections\n",
      "    # Initial deltas\n",
      "    delta = self.derivOfCostFunction(inputValueList[-1], yy) * derivActivationFunction(layerOutputValues[-1])\n",
      "\n",
      "    gradC_b[-1] = delta\n",
      "    gradC_w[-1] = np.dot(delta, activationValues[-2].transpose())\n",
      "\n",
      "    # Loop backward thru layers\n",
      "    for layer in xrange(2, self.num_layers):\n",
      "\n",
      "      layerOutputValue = layerOutputValues[-layer]\n",
      "      derivActivation = derivActivationFunction(layerOutputValue)\n",
      "  \n",
      "      delta = np.dot(self.weights[-layer + 1].transpose(), delta)*derivActivation\n",
      "\n",
      "      gradC_b[-layer] = delta\n",
      "      gradC_w[-layer] = np.dot(delta, activationValues[-layer-1].transpose())\n",
      "    \n",
      "    # Return updated gradients\n",
      "    return(gradC_w, gradC_b)\n",
      " \n",
      "  # Derivative of the cost function with respect to output values\n",
      "  def derivOfCostFunction(self, xx, yy):\n",
      "\n",
      "    return (xx - yy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = NeuralNet([20*28, 20, 6])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.weights[1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "(6, 20)"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}